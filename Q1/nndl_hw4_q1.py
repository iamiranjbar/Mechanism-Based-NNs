# -*- coding: utf-8 -*-
"""NNDL HW4 Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b14i8lS1xDtdRWHZccHYTLtT7UfG-ov5

# Question 1 (SOM)

### Import libraries
"""

import time
import math
import numpy as np
import matplotlib.pyplot as plt
from random import randrange
from tensorflow.keras.datasets import mnist
from sklearn.preprocessing import StandardScaler

"""## SOM Class implementation"""

class SOM:

  def __init__(self, input_size, output_size, neighborhood_indices,
               learning_rate=0.5, max_epochs=100):
    self.input_size = input_size
    self.output_size = output_size
    self.weights = self.create_random_weights()
    self.neighborhood_indices = neighborhood_indices
    self.learning_rate = learning_rate
    self.max_epochs = max_epochs

  def create_random_weights(self):
    weights = []
    for _ in range(self.input_size):
      random_weights = np.random.normal(0.5, 0.2, self.output_size)
      weights.append(random_weights)
    weights = np.array(weights)
    return weights

  def plot_output_neuron_weights(self, index):
    weight = self.weights.T[index]
    reshaped_weight = weight.reshape(28, 28)
    plt.title('Neuron {} weight matrix'.format(index))
    plt.imshow(reshaped_weight, cmap='gray')
    plt.show()

  def train(self, x_train):
    epoch = 0
    while epoch < self.max_epochs:
      for data in x_train:
        data = data.flatten()
        distances = ((self.weights.T - data) ** 2).sum(axis=1)
        min_index = np.argmin(distances)
        to_be_update_indices = [min_index]
        for offset in self.neighborhood_indices:
          new_index = min_index + offset
          if new_index >=0 and new_index < self.output_size:
            to_be_update_indices.append(new_index)
        for j in to_be_update_indices:
            self.weights.T[j] += (self.learning_rate * (data - self.weights.T[j]))
        self.learning_rate *= 0.9999
      epoch += 1
      print(f"Epoch: {epoch}")
    
  def test(self, x_test, y_test):
    real_node_labels = [{digit:0 for digit in range(10)} for _ in range(self.output_size)]
    data_clusters = [list() for _ in range(self.output_size)]
    winner_nodes = set()

    for index, data in enumerate(x_test):
      data = data.flatten()
      label = y_test[index]
      distances = ((self.weights.T - data) ** 2).sum(axis=1)
      min_index = np.argmin(distances)
      winner_nodes.add(min_index)
      real_node_labels[min_index][label] += 1
      data_clusters[min_index].append(data)

    print(f"Winner nodes count: {len(winner_nodes)}")
    for node in winner_nodes:
      print(f"Node number: {node}")
      print(f"Correct labels count in node: {real_node_labels[node]}")
      self.plot_output_neuron_weights(node)

"""## Load data from keras """

(x_train, y_train), (x_test, y_test) = mnist.load_data()

train_random_set = set()
train_random_indices = list()
while len(train_random_indices) != 2000:
  random_index = randrange(x_train.shape[0])
  if random_index not in train_random_set:
    train_random_set.add(random_index)
    train_random_indices.append(random_index)
x_train = x_train[train_random_indices]
y_train = y_train[train_random_indices]

test_random_set = set()
test_random_indices = list()
while len(test_random_indices) != 1000:
  random_index = randrange(x_test.shape[0])
  if random_index not in test_random_set:
    test_random_set.add(random_index)
    test_random_indices.append(random_index)
x_test = x_test[test_random_indices]
y_test = y_test[test_random_indices]

"""### Check each class data balance"""

cnt = {}
for label in y_train:
  if label not in cnt:
    cnt[label] = 1
  else:
    cnt[label] += 1
print("Train labels:")
print(cnt)

cnt = {}
for label in y_test:
  if label not in cnt:
    cnt[label] = 1
  else:
    cnt[label] += 1
print("Test labels:")
print(cnt)

"""## Test SOM without any neighborhood"""

base_som = SOM(28*28, 625, [], max_epochs=40, learning_rate=0.1)
train_start_time = time.time()
base_som.train(x_train)
train_time = time.time() - train_start_time
print(f"Train time: {train_time} s")
base_som.test(x_test, y_test)

"""## Test SOM with R=2 linear neighborhood"""

neighborhood = [-2, -1, 1, 2]
linear_som = SOM(28*28, 625, neighborhood, max_epochs=40, learning_rate=0.15)
train_start_time = time.time()
linear_som.train(x_train)
train_time = time.time() - train_start_time
print(f"Train time: {train_time} s")
linear_som.test(x_test, y_test)

"""## Test SOM with R=1 Square neighborhood"""

neighborhood = [-26, -25, -24, -1, 1, 24, 25, 26]
square_som = SOM(28*28, 625, neighborhood, max_epochs=40, learning_rate=0.15)
train_start_time = time.time()
square_som.train(x_train)
train_time = time.time() - train_start_time
print(f"Train time: {train_time} s")
square_som.test(x_test, y_test)